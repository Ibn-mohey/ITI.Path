{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model selction tools\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\\\n",
    "        , StratifiedKFold , TimeSeriesSplit,KFold,cross_val_score\n",
    "#metrics \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error\n",
    "#models \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor,BaggingRegressor,GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "#tools\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,BaggingRegressor,GradientBoostingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.utils import shuffle\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_path = r\"train.csv\"\n",
    "test_path = r\"test.csv\"\n",
    "df_train = pd.read_csv(train_path,parse_dates=['datetime'],dayfirst=True)\n",
    "df_test = pd.read_csv(test_path,parse_dates=['datetime'],dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_attributes(DF,Date_Col_name):\n",
    "    \n",
    "    DF['Year'] = DF[Date_Col_name].dt.year.astype('int')\n",
    "    DF['Week'] = DF[Date_Col_name].dt.isocalendar().week.astype('int')\n",
    "    DF['Month'] = DF[Date_Col_name].dt.month.astype('int')\n",
    "    DF['WeekDay'] = DF[Date_Col_name].dt.weekday.astype('int')\n",
    "    DF['Hour'] = DF['datetime'].dt.hour\n",
    "    return DF\n",
    "\n",
    "def new_feature(DF,function,new_col_name):\n",
    "    DF[new_col_name]  = DF.apply(function,axis=1)\n",
    "    return DF\n",
    "\n",
    "def map_colmun_to_Categorical(DF,new_col_name,from_vals,to_vals):\n",
    "    DF[new_col_name].replace(from_vals,to_vals,inplace=True)\n",
    "    return DF\n",
    "def CreateLag(DF,used_col,shift = -1):\n",
    "    col_name = f'{used_col}_shift({shift})'\n",
    "    DF[col_name] = DF[used_col].shift(shift)\n",
    "    DF[col_name].fillna(0, inplace=True)\n",
    "    return DF\n",
    "def CreateRoll(DF,used_col,roll = 4):\n",
    "    col_name = f'{used_col}_rolling({roll}With_Mean)'\n",
    "    DF[col_name] = DF[used_col].rolling(roll).mean()\n",
    "    DF[col_name].fillna(0, inplace=True)\n",
    "    return DF\n",
    "def CreateEWM(DF,used_col,com = 0.9):\n",
    "    col_name = f'{used_col}_EWM_Com({com}With_Mean)'\n",
    "    DF[col_name] = DF[used_col].ewm(com=com).mean()\n",
    "    DF[col_name].fillna(0, inplace=True)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_date_attributes(df_train,'datetime')\n",
    "df_test = get_date_attributes(df_test,'datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rush_hour(df):\n",
    "    #from 8 am , 6 pm\n",
    "    rush_range_1 = 2 # around the rush hour by +- 2 hrs\n",
    "    rush_range_2 = 5 # around the rush hour by +- 4 hrs\n",
    "    is_functional = df['workingday'] \n",
    "    \n",
    "    if (abs(df['Hour'] - 8) <= rush_range_1): \n",
    "        return np.exp(-abs(df['Hour'] - 8)) * is_functional\n",
    "    \n",
    "    elif (abs(df['Hour'] - 18) <= rush_range_2):\n",
    "        return np.exp(-abs(df['Hour'] - 18)) * is_functional\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def dead_hour(df):\n",
    "    #dead_range_1 = 5 # around the dead hour by +- 3 hrs from 4 am\n",
    "    is_functional = df['workingday'] \n",
    "    \n",
    "    if(df['Hour'] in [22,23,0,1,2,3,4,5]):\n",
    "        return np.exp(-abs(df['Hour'] - 4)) * is_functional\n",
    "    else:\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_state = lambda df : 1  if (df['Hour'] >=6 and df['Hour'] <=18) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ideal = lambda df: 1 if (df['temp'] < 30 and df['windspeed'] > 30) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = new_feature(df_train,rush_hour,'rush_hour')\n",
    "df_train = new_feature(df_train,dead_hour,'dead_hour')\n",
    "df_train = new_feature(df_train,day_state,'day_state')\n",
    "df_train = new_feature(df_train,Ideal,'Ideal')\n",
    "\n",
    "df_test = new_feature(df_test,rush_hour,'rush_hour')\n",
    "df_test = new_feature(df_test,dead_hour,'dead_hour')\n",
    "df_test = new_feature(df_test,day_state,'day_state')\n",
    "df_test = new_feature(df_test,Ideal,'Ideal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ColsForLag =  [\"temp\" ,\"weather\" ,\"rush_hour\",\"dead_hour\",\"humidity\",\"windspeed\",\"Ideal\"]\n",
    "\n",
    "t  = -1\n",
    "for col in ColsForLag:\n",
    "    df_train = CreateLag(df_train,col,(+t))\n",
    "for col in ColsForLag:\n",
    "    df_train = CreateLag(df_train,col,(+t-1))\n",
    "for col in ColsForLag:\n",
    "    df_train = CreateLag(df_train,col,(+t-2))\n",
    "for col in  ColsForLag:\n",
    "    df_train = CreateRoll(df_train,col,4)\n",
    "for col in  ColsForLag:\n",
    "    df_train = CreateEWM(df_train,col,0.9)\n",
    "    \n",
    "for col in ColsForLag:\n",
    "    df_test = CreateLag(df_test,col,(+t))\n",
    "for col in ColsForLag:\n",
    "    df_test = CreateLag(df_test,col,(+t-1))\n",
    "for col in ColsForLag:\n",
    "    df_test = CreateLag(df_test,col,(+t-2))\n",
    "for col in  ColsForLag:\n",
    "    df_test = CreateRoll(df_test,col,4)\n",
    "for col in  ColsForLag:\n",
    "    df_test = CreateEWM(df_test,col,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag1_features , lag2_features , lag3_features , rolling_features,ewn_features = [],[],[],[],[]\n",
    "t = -1\n",
    "\n",
    "for used_col in ColsForLag:\n",
    "    col_name = f'{used_col}_shift({+t})'\n",
    "    lag1_features.append(col_name)\n",
    "    \n",
    "for used_col in ColsForLag:\n",
    "    col_name = f'{used_col}_shift({+t-1})'\n",
    "    lag2_features.append(col_name)\n",
    "    \n",
    "for used_col in ColsForLag:\n",
    "    col_name = f'{used_col}_shift({+t-2})'\n",
    "    lag3_features.append(col_name)\n",
    "\n",
    "for used_col in ColsForLag:\n",
    "    col_name = f'{used_col}_rolling({4}With_Mean)'\n",
    "    rolling_features.append(col_name)\n",
    "\n",
    "for used_col in ColsForLag:\n",
    "    col_name = f'{used_col}_EWM_Com({0.9}With_Mean)'\n",
    "    ewn_features.append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = ['Hour','Week', 'Month','Year','windspeed'\n",
    "                     ,'WeekDay','humidity','workingday','season','weather','Ideal']\n",
    "\n",
    "weather_features=['rush_hour','dead_hour','day_state']\n",
    "\n",
    "selected_features = original_features + weather_features + lag1_features + lag2_features + lag3_features + rolling_features + ewn_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"count\"] = np.log(df_train[\"count\"]+0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df_train[selected_features]\n",
    "y1 = df_train[\"count\"]\n",
    "\n",
    "# tss = TimeSeriesSplit(n_splits=2)\n",
    "# train_ind,test_ind  = tss.split(X1,groups=[20,1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size = 0.2, random_state=42,shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred, convertExp=True):\n",
    "    if convertExp:\n",
    "        y_true = 10**(y_true)\n",
    "        y_pred = 10**(y_pred)\n",
    "        \n",
    "    log_true = np.nan_to_num(np.array([np.log(y+1.0) for y in y_true]))\n",
    "    log_pred = np.nan_to_num(np.array([np.log(y+1.0) for y in y_pred]))\n",
    "    \n",
    "    output = np.sqrt(np.mean((log_true - log_pred)**2))\n",
    "    return output\n",
    "\n",
    "rmsle_scorer = metrics.make_scorer(rmsle, greater_is_better=False) \n",
    "Scoring = rmsle_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Test) CatBoost Regression RMSLE: 0.6530851835663867\n",
      "(Train) CatBoost Regression RMSLE: 0.4263422353107868\n"
     ]
    }
   ],
   "source": [
    "train_dataset = cb.Pool(X_train, y_train) \n",
    "test_dataset = cb.Pool(X_test, y_test)\n",
    "\n",
    "# model = cb.CatBoostRegressor(loss_function='RMSE',random_state=0,max_depth=4,iterations=3200,\n",
    "#                                            l2_leaf_reg=1,learning_rate=0.038,subsample=0.85)\n",
    "\n",
    "model = cb.CatBoostRegressor(silent=True,loss_function='RMSE')\n",
    "model.fit(X_train,y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "pred_train= model.predict(X_train)\n",
    "\n",
    "print('(Test) CatBoost Regression RMSLE:', rmsle(y_test, pred_test, True))\n",
    "print('(Train) CatBoost Regression RMSLE:', rmsle(y_train, pred_train, True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Test) CatBoost Regression RMSLE: 0.6944264919951119\n",
      "(Train) CatBoost Regression RMSLE: 0.5040575710908287\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\n",
    "gbm_model = GradientBoostingRegressor(**params)\n",
    "gbm_model.fit(X_train,y_train)\n",
    "\n",
    "pred_test = gbm_model.predict(X_test)\n",
    "pred_train= gbm_model.predict(X_train)\n",
    "\n",
    "print('(Test) CatBoost Regression RMSLE:', rmsle(y_test, pred_test, True))\n",
    "print('(Train) CatBoost Regression RMSLE:', rmsle(y_train, pred_train, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['count'] =  np.exp(model.predict(df_test[selected_features]))\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "save_to_path = r'submission.csv'\n",
    "final_df.to_csv(save_to_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
